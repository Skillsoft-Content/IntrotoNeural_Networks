{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b28a8c0",
   "metadata": {},
   "source": [
    "## INTROTONEURALNETWORKS/3 INTROTOTENSORFLOW/INTROTONEURALNETWORKS INTROTOTENSORFLOW 2 EXERCISE  ##\n",
    "#### Exercise ####\n",
    "#### Please refer to module 2 of IntroToNeuralNetworks - IntroToTensorflow for Tasks 1-7\n",
    "#### Task 1 \n",
    "##### Load the libraries that are used in this module.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d27715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba560afb",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Define the data directory.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566b489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae93e3a2",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Load the dataset `bank_marketing.csv` and save it to `bank_marketing`.\n",
    "##### Print the first few rows of `bank_marketing`.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66b3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4537d22",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Define a convenience function `ex_data_prep` to perform the data cleaning steps mentioned below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Replace the column `y` in the dataframe, by setting it to 1 if `y` is 'yes', otherwise set `y` to 0.\n",
    "2. Perform one hot encoding on the variables with data type object (i.e `job`, `marital`, `education`, `default`, `housing`, `loan`, `contact`, `month`, `day_of_week` and `poutcome`) except the target variable `y`\n",
    "3. Drop the original variables and concatenate the dummies to original datset\n",
    "4. Select the predictors by dropping variable `y` and save the result to a dataframe `X_ex`\n",
    "5. Save the target variable `y` column to `y_ex` variable\n",
    "6. Set the seed to 1\n",
    "7. Split the data into training, test, and validation sets with 70:15:15 ratio and save respective variables to `X_train_ex`, `X_test_ex`, `X_val_ex`, `y_train_ex`, `y_test_ex`, `y_val_ex`\n",
    "8. Scale the train, test and the validation datasets using Min max scaler and save as `X_train_scaled_ex`, `X_test_scaled_ex` and `X_val_scaled_ex` respectiely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c844abc",
   "metadata": {},
   "source": [
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e16ccfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c84534",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Initialize a simple sequential neural network model with 32 neurons for the 1st hidden layer, 20 neurons for the second layer, and appropriate input and output layers. Name the model `model_ex`.\n",
    "##### Compile the model using the \"adam\" optimizer and \"binary_crossentropy\" loss, and use \"accuracy\" as a metric.\n",
    "##### Fit the model using train and validation sets with 200 epochs, and assign it to `model_res_ex` variable.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c50eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238297e1",
   "metadata": {},
   "source": [
    "## Set up model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ex = Sequential([\n",
    "  Dense(32,                                         #<- number of neurons for 1st hidden layer\n",
    "        input_shape = (X_train_scaled_ex.shape[1], )), #<- input layer shape: `(num_features, )`\n",
    "  Dense(20,                                         #<- add 2nd hidden layer with 20 neurons\n",
    "        activation = 'relu'), #<- set activation function for hidden layer\n",
    "  Dense(1,                    #<- add output layer with single neuron \n",
    "       activation = 'sigmoid')#<- activation function for output layer       \n",
    "])\n",
    "# Compile the model.\n",
    "model_ex.compile(optimizer = \"adam\",\n",
    "                 loss = \"binary_crossentropy\",\n",
    "                 metrics = [\"accuracy\"])\n",
    "                 \n",
    "# Fitting the model\n",
    "model_res_ex = model_ex.fit(X_train_scaled_ex, y_train_ex,                 #<- train data and labels\n",
    "                      validation_data = (X_val_scaled_ex, y_val_ex),       #<- pass validation data\n",
    "                      epochs = 200)                                        #<- specify number of epochs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d660f61",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Plot accuracy and loss curves for `model_res_ex`. \n",
    "##### You can access them by checking the `model_res_ex.history` dictionary.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432de772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e43a53f0",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Evaluate the model on the test data. Save loss as `loss_ex` and accuracy as `accuracy_ex`. Print the loss and accuracy values.\n",
    "##### Predict the labels on test data for the model and save as `y_pred_ex`. \n",
    "##### Check how the values look.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832f962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
